{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791079af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from multiprocessing import Pool\n",
    "from langdetect_drop_column import process_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0591b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the maximum column width to a large value to prevent text wrapping\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd56e8b6",
   "metadata": {},
   "source": [
    "# Read listing csv files into dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ef69f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read listings.csv into df\n",
    "df_atd_list = pd.read_csv('../../cities/amsterdam/listings.csv', low_memory=False)\n",
    "df_ldn_list = pd.read_csv('../../cities/london/listings2_London.csv', low_memory=False)\n",
    "df_nyc_list = pd.read_csv('../../cities/new york/listings2_Newyork.csv', low_memory=False)\n",
    "df_prs_list = pd.read_csv('../../cities/paris/listings2_Paris.csv', low_memory=False)\n",
    "df_rom_list = pd.read_csv('../../cities/rome/listings2_Rome.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6013ba50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe and name list\n",
    "df_lists = [df_atd_list, df_ldn_list, df_nyc_list, df_prs_list, df_rom_list]\n",
    "list_names = ['atd_list', 'ldn_list', 'nyc_list', 'prs_list', 'rom_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f696a02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of columns to keep\n",
    "# there are more unwanted columns than wanted. make sense to list out lesser items.\n",
    "col_to_keep = ['id', 'name', 'host_since', 'host_location', 'host_is_superhost', 'host_identity_verified',\n",
    "               'property_type', 'price', 'review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness',\n",
    "               'review_scores_checkin', 'review_scores_communication', 'review_scores_location', 'review_scores_value']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424615b3",
   "metadata": {},
   "source": [
    "# Remove unwanted columns and special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e94e5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loop to remove:\n",
    "# 1. unwanted columns\n",
    "# 2. unwanted details from 'name' and 'host_location' columns\n",
    "# 3. save cleaned dataframes to csv\n",
    "for df, list_name in zip(df_lists, list_names):\n",
    "    # remove unwanted columns.\n",
    "    df = df.loc[:, col_to_keep]\n",
    "    \n",
    "    # clean up name column. remove everything from the first non-alphanumeric character\n",
    "    # define a regular expression pattern to match the first non-alphanumeric character\n",
    "    pattern = r'[^a-zA-Z0-9\\s]'\n",
    "\n",
    "    # remove the portion of the string starting from the first non-alphanumeric character\n",
    "    df['name'] = df['name'].apply(lambda x: re.split(pattern, x)[0].strip())\n",
    "\n",
    "    # convert id column to integer\n",
    "    # df = df[pd.to_numeric(df['id'], errors='coerce').notna()]\n",
    "    \n",
    "    # remove '$' and ',' from 'price' column, and keeping the numbers as float\n",
    "    df['price'] = df['price'].str.replace('[$,]', '', regex=True).astype(float).round(2)\n",
    "\n",
    "    # Find the most common 'host_location' value\n",
    "    most_common_location = df['host_location'].value_counts().idxmax()\n",
    "\n",
    "    # Filter the DataFrame based on the most common location\n",
    "    # This avoids hard coding a value like \"Amsterdam, Netherlands\"\n",
    "    df = df[df['host_location'] == most_common_location]\n",
    "\n",
    "    # df to csv\n",
    "    df.to_csv(f'../../csv_cleaned/{list_name}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b89447",
   "metadata": {},
   "source": [
    "# < br/ > creates extra rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711cdd34",
   "metadata": {},
   "source": [
    "<img src=\"../../images/br.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d4a203",
   "metadata": {},
   "source": [
    "# Preprocess review csv files BEFORE reading into dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ceb62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the CSV file to replace <br/> and handle line breaks\n",
    "# create a list of raw csv\n",
    "raw_csvs = ['amsterdam/reviews.csv',\n",
    "            'london/reviews2_London.csv',\n",
    "            'new york/reviews2_Newyork.csv',\n",
    "            'paris/reviews2_Paris.csv',\n",
    "            'rome/reviews2_Rome.csv']\n",
    "\n",
    "# create a list of processed csv names\n",
    "processed_csv_names = ['amsterdam/p_reviews.csv',\n",
    "                       'london/p_reviews2_London.csv',\n",
    "                       'new york/p_reviews2_Newyork.csv',\n",
    "                       'paris/p_reviews2_Paris.csv',\n",
    "                       'rome/p_reviews2_Rome.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cd1c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for raw_csv, processed_csv_name in zip(raw_csvs, processed_csv_names):\n",
    "    with (open(f'../../cities/{raw_csv}', 'r', encoding='utf-8') as infile,\n",
    "          open(f'../../cities/{processed_csv_name}', 'w', encoding='utf-8') as outfile):\n",
    "        for line in infile:\n",
    "            # Replace <br/> with a space\n",
    "            line = line.replace('<br/>', ' ')\n",
    "            outfile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a6e94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read reviews.csv into df\n",
    "df_atd_rev = pd.read_csv('../../cities/amsterdam/p_reviews.csv')\n",
    "df_ldn_rev = pd.read_csv('../../cities/london/p_reviews2_London.csv')\n",
    "df_nyc_rev = pd.read_csv('../../cities/new york/p_reviews2_Newyork.csv')\n",
    "df_prs_rev = pd.read_csv('../../cities/paris/p_reviews2_Paris.csv')\n",
    "df_rom_rev = pd.read_csv('../../cities/rome/p_reviews2_Rome.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb930c74",
   "metadata": {},
   "source": [
    "# Parallel processing to optimize the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca91b45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # create dataframe and name list\n",
    "    df_revs = [df_atd_rev, df_ldn_rev, df_nyc_rev, df_prs_rev, df_rom_rev]\n",
    "    rev_names = ['p_atd_rev', 'p_ldn_rev', 'p_nyc_rev', 'p_prs_rev', 'p_rom_rev']\n",
    "\n",
    "    # list of unwanted columns.\n",
    "    unwanted_col = ['id', 'reviewer_id', 'reviewer_name']\n",
    "\n",
    "    # create a pool of processes\n",
    "    num_processes = os.cpu_count() - 1\n",
    "    pool = Pool(num_processes)\n",
    "\n",
    "    # apply the processing function to dataframes in parallel\n",
    "    processed_dfs = pool.starmap(process_dataframe, [(df_r, unwanted_col) for df_r in df_revs])\n",
    "\n",
    "    # close and join the pool\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    # for loop to save cleaned dataframes to csv\n",
    "    for df, rev_name in zip(processed_dfs, rev_names):\n",
    "        df.to_csv(f'../../csv_cleaned/{rev_name}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
